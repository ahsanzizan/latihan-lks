{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'halo hai ada asiknya keren adalah mengapa begitu pokok laku'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "stemmer.stem(\"Halo hai ada asiknya kerennya adalah mengapa begitulah pokoknya dilakukan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_knn(new_vector: np.ndarray, tfidf_matrix: np.ndarray, labels: np.ndarray, k=3):\n",
    "    similarities = [cosine_similarity(new_vector, tfidf_vector) for tfidf_vector in tfidf_matrix]\n",
    "    top_indices = np.argsort(similarities)[-k:]\n",
    "    label_votes = [labels[i] for i in top_indices]\n",
    "    print(label_votes)\n",
    "    prediction = max(set(label_votes), key=label_votes.count)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog jumped over the fence\",\n",
    "    \"The cat and the dog are friends\",\n",
    "    \"Cat and dog live in the same house\",\n",
    "    \"They both got angry\"\n",
    "]\n",
    "labels = ['cat', 'dog', 'both', 'both', 'both']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(documents, columns=['texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the mat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog jumped over the fence</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cat and the dog are friends</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat and dog live in the same house</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They both got angry</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                texts labels\n",
       "0              The cat sat on the mat    cat\n",
       "1       The dog jumped over the fence    dog\n",
       "2     The cat and the dog are friends   both\n",
       "3  Cat and dog live in the same house   both\n",
       "4                 They both got angry   both"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat sat mat',\n",
       " 'dog jump fenc',\n",
       " 'cat dog friend',\n",
       " 'cat dog live hous',\n",
       " 'got angri']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english')) # indonesian for Bahasa\n",
    "\n",
    "word_set = set()\n",
    "preprocessed_documents = [] \n",
    "\n",
    "for document in documents:\n",
    "    # Tokenize the document\n",
    "    words = word_tokenize(document.lower())\n",
    "    \n",
    "    # Remove stop words and stem the remaining words\n",
    "    stemmed_words = [porter.stem(word) for word in words if word not in stop_words]\n",
    "    word_set.update(stemmed_words)\n",
    "    \n",
    "    preprocessed_documents.append(' '.join(stemmed_words))\n",
    "\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(word_set)}\n",
    "\n",
    "tfidf_matrix = np.zeros((len(preprocessed_documents), len(word_set)))\n",
    "\n",
    "for i, document in enumerate(preprocessed_documents):\n",
    "    words = document.split()\n",
    "    word_count = {word: words.count(word) for word in set(words)}\n",
    "    for word, count in word_count.items():\n",
    "        tf = count / len(words)\n",
    "        idf = np.log(len(documents) / (1 + sum(word in document for document in preprocessed_documents)))\n",
    "        tfidf_matrix[i, word_to_index[word]] = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jump': 0,\n",
       " 'friend': 1,\n",
       " 'cat': 2,\n",
       " 'sat': 3,\n",
       " 'hous': 4,\n",
       " 'dog': 5,\n",
       " 'mat': 6,\n",
       " 'got': 7,\n",
       " 'fenc': 8,\n",
       " 'live': 9,\n",
       " 'angri': 10}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_matrix, columns=[item[0] for item in list(word_to_index.items())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jump</th>\n",
       "      <th>friend</th>\n",
       "      <th>cat</th>\n",
       "      <th>sat</th>\n",
       "      <th>hous</th>\n",
       "      <th>dog</th>\n",
       "      <th>mat</th>\n",
       "      <th>got</th>\n",
       "      <th>fenc</th>\n",
       "      <th>live</th>\n",
       "      <th>angri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.055786</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.229073</td>\n",
       "      <td>0.055786</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.229073</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.458145</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      jump   friend       cat      sat      hous       dog      mat       got  \\\n",
       "0  0.00000  0.00000  0.074381  0.30543  0.000000  0.000000  0.30543  0.000000   \n",
       "1  0.30543  0.00000  0.000000  0.00000  0.000000  0.074381  0.00000  0.000000   \n",
       "2  0.00000  0.30543  0.074381  0.00000  0.000000  0.074381  0.00000  0.000000   \n",
       "3  0.00000  0.00000  0.055786  0.00000  0.229073  0.055786  0.00000  0.000000   \n",
       "4  0.00000  0.00000  0.000000  0.00000  0.000000  0.000000  0.00000  0.458145   \n",
       "\n",
       "      fenc      live     angri  \n",
       "0  0.00000  0.000000  0.000000  \n",
       "1  0.30543  0.000000  0.000000  \n",
       "2  0.00000  0.000000  0.000000  \n",
       "3  0.00000  0.229073  0.000000  \n",
       "4  0.00000  0.000000  0.458145  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The cat and the dog are playing together\" # Text to predict\n",
    "new_words = word_tokenize(input_text.lower())\n",
    "stemmed_new_words = [porter.stem(word) for word in new_words if word not in stop_words]\n",
    "new_tfidf_vector = np.zeros(len(word_set))\n",
    "\n",
    "for word in stemmed_new_words:\n",
    "    if word in word_to_index:\n",
    "        tf = stemmed_new_words.count(word) / len(stemmed_new_words)\n",
    "        idf = np.log(len(documents) / (1 + sum(word in document for document in preprocessed_documents)))\n",
    "        new_tfidf_vector[word_to_index[word]] = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'both', 'both']\n",
      "Predicted label: both\n"
     ]
    }
   ],
   "source": [
    "predicted_label = predict_with_knn(new_tfidf_vector, tfidf_matrix, labels)\n",
    "\n",
    "print(\"Predicted label:\", predicted_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
